{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_classification.datasets import FolderOfFrameFoldersDataset, FrameWindowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"/home/ubuntu/SupervisedVideoClassification\")\n",
    "DATA_ROOT = Path(ROOT/\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    torchvision.transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomVerticalFlip(p=0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FolderOfFrameFoldersDataset(DATA_ROOT/'train', \n",
    "                                       transform=train_transforms, \n",
    "                                       base_class=FrameWindowDataset,\n",
    "                                       window_size=3,\n",
    "                                       overlapping=True,)\n",
    "valid_ds = FolderOfFrameFoldersDataset(DATA_ROOT/'validation', \n",
    "                                       transform=valid_transforms, \n",
    "                                       base_class=FrameWindowDataset,\n",
    "                                       window_size=3,\n",
    "                                       overlapping=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from video_classification.models.single_image import SingleImageModel\n",
    "from video_classification.models.mlp import MLP\n",
    "\n",
    "\n",
    "class MultiImageModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 window_size=3,\n",
    "                 single_mlp_sizes=[768, 128],\n",
    "                 joint_mlp_sizes=[64, 2]):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.single_mlp_sizes = single_mlp_sizes\n",
    "        self.joint_mlp_sizes = joint_mlp_sizes\n",
    "        \n",
    "        self.single_image_model = SingleImageModel(self.single_mlp_sizes)\n",
    "        self.in_features = self.single_mlp_sizes[-1] * self.window_size\n",
    "        self.clf = MLP(self.in_features, joint_mlp_sizes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of size [B, T, C, H, W]. In other words, a batch of windows.\n",
    "        # each img for the same window goes through SingleImageModel\n",
    "        x = x.transpose(0, 1)  # -> [T, B, C, H, W]\n",
    "        x = torch.cat([self.single_image_model(window) for window in x], 1)\n",
    "        # x is now of size [B, T * single_mlp_sizes[-1]]\n",
    "        \n",
    "        x = self.clf(x)\n",
    "        # Now size is [B, joint_mlp_sizes[-1]] which should always be 2\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def freeze_single_image_model(self):\n",
    "        # Freeze the VGG classifier\n",
    "        for p in self.single_image_model.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze_single_image_model(self):\n",
    "        # Unfreeze the VGG classifier. Training the whole VGG is a no-go, so we only train the classifier part.\n",
    "        for p in self.single_image_model.clf.parameters():\n",
    "            p.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiImageModel(\n",
    "                 window_size=3,\n",
    "                 single_mlp_sizes=[1024, 256],\n",
    "                 joint_mlp_sizes=[128, 2])\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([train_ds[0][0], train_ds[1][0], train_ds[2][0], train_ds[3][0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1265, -0.1215],\n",
       "        [-0.2513, -0.5642],\n",
       "        [ 0.0864,  0.3089],\n",
       "        [-0.2790,  0.4778]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_classification.trainer import Trainer\n",
    "\n",
    "classes_weights = torch.Tensor([0.3, 1.0]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(train_ds, \n",
    "                  valid_ds, \n",
    "                  model, \n",
    "                  criterion,\n",
    "                  \"multi_frame_vgg_from_scratch\",\n",
    "                  str(ROOT/'checkpoints'),\n",
    "                  device=device,\n",
    "                  amp_opt_level=\"O1\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1: Avg accuracy: 0.94 |Precision: 0.96, 0.59 |Recall: 0.97, 0.51 | F1: 0.76 | Avg loss: 0.41\n",
      "Validation Results - Epoch: 1: Avg accuracy: 0.68 |Precision: 0.93, 0.12 |Recall: 0.70, 0.43 | F1: 0.50 | Avg loss: 0.68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 2: Avg accuracy: 0.95 |Precision: 0.96, 0.87 |Recall: 0.99, 0.44 | F1: 0.78 | Avg loss: 0.31\n",
      "Validation Results - Epoch: 2: Avg accuracy: 0.91 |Precision: 0.94, 0.49 |Recall: 0.97, 0.31 | F1: 0.66 | Avg loss: 0.42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 3: Avg accuracy: 0.96 |Precision: 0.96, 0.96 |Recall: 1.00, 0.43 | F1: 0.79 | Avg loss: 0.29\n",
      "Validation Results - Epoch: 3: Avg accuracy: 0.87 |Precision: 0.93, 0.27 |Recall: 0.92, 0.31 | F1: 0.61 | Avg loss: 0.50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 4: Avg accuracy: 0.96 |Precision: 0.96, 0.94 |Recall: 1.00, 0.46 | F1: 0.80 | Avg loss: 0.28\n",
      "Validation Results - Epoch: 4: Avg accuracy: 0.92 |Precision: 0.93, 0.73 |Recall: 0.99, 0.20 | F1: 0.64 | Avg loss: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 5: Avg accuracy: 0.95 |Precision: 0.96, 0.85 |Recall: 0.99, 0.47 | F1: 0.79 | Avg loss: 0.27\n",
      "Validation Results - Epoch: 5: Avg accuracy: 0.84 |Precision: 0.93, 0.21 |Recall: 0.89, 0.31 | F1: 0.58 | Avg loss: 0.54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 6: Avg accuracy: 0.95 |Precision: 0.96, 0.82 |Recall: 0.99, 0.49 | F1: 0.79 | Avg loss: 0.26\n",
      "Validation Results - Epoch: 6: Avg accuracy: 0.91 |Precision: 0.93, 0.48 |Recall: 0.97, 0.27 | F1: 0.65 | Avg loss: 0.41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 7: Avg accuracy: 0.95 |Precision: 0.95, 0.98 |Recall: 1.00, 0.39 | F1: 0.77 | Avg loss: 0.32\n",
      "Validation Results - Epoch: 7: Avg accuracy: 0.90 |Precision: 0.93, 0.40 |Recall: 0.97, 0.23 | F1: 0.62 | Avg loss: 0.48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 8: Avg accuracy: 0.96 |Precision: 0.96, 0.84 |Recall: 0.99, 0.53 | F1: 0.81 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 8: Avg accuracy: 0.77 |Precision: 0.93, 0.16 |Recall: 0.81, 0.36 | F1: 0.54 | Avg loss: 0.68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Training Results - Epoch: 9: Avg accuracy: 0.95 |Precision: 0.96, 0.73 |Recall: 0.98, 0.55 | F1: 0.80 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 9: Avg accuracy: 0.90 |Precision: 0.93, 0.41 |Recall: 0.96, 0.27 | F1: 0.64 | Avg loss: 0.47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 10: Avg accuracy: 0.96 |Precision: 0.96, 0.90 |Recall: 1.00, 0.46 | F1: 0.79 | Avg loss: 0.28\n",
      "Validation Results - Epoch: 10: Avg accuracy: 0.90 |Precision: 0.93, 0.37 |Recall: 0.97, 0.21 | F1: 0.61 | Avg loss: 0.56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 11: Avg accuracy: 0.95 |Precision: 0.96, 0.73 |Recall: 0.98, 0.53 | F1: 0.80 | Avg loss: 0.24\n",
      "Validation Results - Epoch: 11: Avg accuracy: 0.92 |Precision: 0.93, 0.56 |Recall: 0.98, 0.28 | F1: 0.66 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Training Results - Epoch: 12: Avg accuracy: 0.96 |Precision: 0.96, 0.96 |Recall: 1.00, 0.47 | F1: 0.80 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 12: Avg accuracy: 0.91 |Precision: 0.93, 0.47 |Recall: 0.97, 0.25 | F1: 0.64 | Avg loss: 0.47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 13: Avg accuracy: 0.96 |Precision: 0.96, 0.96 |Recall: 1.00, 0.49 | F1: 0.81 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 13: Avg accuracy: 0.90 |Precision: 0.93, 0.43 |Recall: 0.96, 0.30 | F1: 0.65 | Avg loss: 0.51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 14: Avg accuracy: 0.96 |Precision: 0.96, 0.97 |Recall: 1.00, 0.48 | F1: 0.81 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 14: Avg accuracy: 0.92 |Precision: 0.93, 0.58 |Recall: 0.98, 0.27 | F1: 0.66 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 15: Avg accuracy: 0.96 |Precision: 0.96, 0.95 |Recall: 1.00, 0.53 | F1: 0.83 | Avg loss: 0.23\n",
      "Validation Results - Epoch: 15: Avg accuracy: 0.92 |Precision: 0.94, 0.54 |Recall: 0.97, 0.31 | F1: 0.67 | Avg loss: 0.41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 16: Avg accuracy: 0.96 |Precision: 0.96, 0.96 |Recall: 1.00, 0.45 | F1: 0.80 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 16: Avg accuracy: 0.92 |Precision: 0.93, 0.64 |Recall: 0.99, 0.24 | F1: 0.65 | Avg loss: 0.42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Training Results - Epoch: 17: Avg accuracy: 0.96 |Precision: 0.96, 0.95 |Recall: 1.00, 0.51 | F1: 0.82 | Avg loss: 0.24\n",
      "Validation Results - Epoch: 17: Avg accuracy: 0.92 |Precision: 0.93, 0.59 |Recall: 0.98, 0.29 | F1: 0.67 | Avg loss: 0.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 18: Avg accuracy: 0.96 |Precision: 0.96, 0.96 |Recall: 1.00, 0.50 | F1: 0.82 | Avg loss: 0.24\n",
      "Validation Results - Epoch: 18: Avg accuracy: 0.93 |Precision: 0.93, 0.79 |Recall: 0.99, 0.26 | F1: 0.68 | Avg loss: 0.48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 19: Avg accuracy: 0.96 |Precision: 0.96, 0.96 |Recall: 1.00, 0.50 | F1: 0.82 | Avg loss: 0.23\n",
      "Validation Results - Epoch: 19: Avg accuracy: 0.92 |Precision: 0.93, 0.61 |Recall: 0.98, 0.26 | F1: 0.66 | Avg loss: 0.47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83beb847c34e48fba160311a0f300cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=556), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a883639fb590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               \u001b[0mmax_gradient_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m              )\n",
      "\u001b[0;32m~/SupervisedVideoClassification/video_classification/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, lr, batch_size, n_epochs, gradient_accumulation_steps, num_workers, max_gradient_norm)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach_common_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mattach_common_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SupervisedVideoClassification/video_classification/trainer/trainer.py\u001b[0m in \u001b[0;36mprocess_fn\u001b[0;34m(self, engine, batch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SupervisedVideoClassification/video_classification/trainer/trainer.py\u001b[0m in \u001b[0;36mprepare_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         return (convert_tensor(\n\u001b[0;32m---> 62\u001b[0;31m             x, device=self.device, non_blocking=self.non_blocking),\n\u001b[0m\u001b[1;32m     63\u001b[0m                 convert_tensor(\n\u001b[1;32m     64\u001b[0m                     y, device=self.device, non_blocking=self.non_blocking))\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/utils.py\u001b[0m in \u001b[0;36mconvert_tensor\u001b[0;34m(input_, device, non_blocking)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/utils.py\u001b[0m in \u001b[0;36mapply_to_tensor\u001b[0;34m(input_, func)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"Apply a function on a tensor or mapping, or sequence of tensors.\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/utils.py\u001b[0m in \u001b[0;36mapply_to_type\u001b[0;34m(input_, input_type, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ignite/utils.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"\"\"Move tensors to relevant device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First 3 epochs: only joint MLP unfrozen, high learning rate\n",
    "\n",
    "trainer.train(lr=1e-3, \n",
    "              batch_size=48, \n",
    "              n_epochs=20,\n",
    "              gradient_accumulation_steps=8,\n",
    "              num_workers=8,\n",
    "              max_gradient_norm=2.0,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>nll</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>0.937559</td>\n",
       "      <td>0.757145</td>\n",
       "      <td>0.413565</td>\n",
       "      <td>[0.9616572414069707, 0.5874125874125874]</td>\n",
       "      <td>[0.9713186145432449, 0.5132382892057027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.679182</td>\n",
       "      <td>0.496446</td>\n",
       "      <td>0.678223</td>\n",
       "      <td>[0.9276335877862596, 0.12414733969986358]</td>\n",
       "      <td>[0.7029153169828783, 0.4343675417661098]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>0.954032</td>\n",
       "      <td>0.781115</td>\n",
       "      <td>0.305601</td>\n",
       "      <td>[0.9573099415204679, 0.8698698698698699]</td>\n",
       "      <td>[0.9947336439133077, 0.4424643584521385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.910989</td>\n",
       "      <td>0.664824</td>\n",
       "      <td>0.417051</td>\n",
       "      <td>[0.9350736278447122, 0.4942084942084942]</td>\n",
       "      <td>[0.9696899583526145, 0.3054892601431981]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>0.956959</td>\n",
       "      <td>0.787474</td>\n",
       "      <td>0.285249</td>\n",
       "      <td>[0.956835649406102, 0.9605411499436303]</td>\n",
       "      <td>[0.9985821348997367, 0.43380855397148677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.865007</td>\n",
       "      <td>0.607937</td>\n",
       "      <td>0.503948</td>\n",
       "      <td>[0.9323626115547206, 0.2712215320910973]</td>\n",
       "      <td>[0.9185562239703841, 0.3126491646778043]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>0.95816</td>\n",
       "      <td>0.798594</td>\n",
       "      <td>0.275739</td>\n",
       "      <td>[0.9588459741473291, 0.9398963730569948]</td>\n",
       "      <td>[0.9976503949767065, 0.46181262729124234]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.92259</td>\n",
       "      <td>0.635217</td>\n",
       "      <td>0.431444</td>\n",
       "      <td>[0.9273827534039334, 0.7280701754385965]</td>\n",
       "      <td>[0.9928273947246645, 0.19809069212410502]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>0.95467</td>\n",
       "      <td>0.790076</td>\n",
       "      <td>0.27285</td>\n",
       "      <td>[0.9592347717225461, 0.8474264705882353]</td>\n",
       "      <td>[0.9932752683816083, 0.4694501018329939]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.838009</td>\n",
       "      <td>0.579599</td>\n",
       "      <td>0.544394</td>\n",
       "      <td>[0.929642166344294, 0.2115702479338843]</td>\n",
       "      <td>[0.8896344285053216, 0.3054892601431981]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>train</th>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.794968</td>\n",
       "      <td>0.264289</td>\n",
       "      <td>[0.9608466855168081, 0.8160337552742616]</td>\n",
       "      <td>[0.9911687259469313, 0.4923625254582485]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.649548</td>\n",
       "      <td>0.412052</td>\n",
       "      <td>[0.9324294287619471, 0.47520661157024796]</td>\n",
       "      <td>[0.9706154558074965, 0.2744630071599045]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>train</th>\n",
       "      <td>0.954632</td>\n",
       "      <td>0.768462</td>\n",
       "      <td>0.315977</td>\n",
       "      <td>[0.9539056457849961, 0.9784537389100126]</td>\n",
       "      <td>[0.9993113226655864, 0.39307535641547864]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.90213</td>\n",
       "      <td>0.61898</td>\n",
       "      <td>0.482983</td>\n",
       "      <td>[0.9280958721704394, 0.40425531914893614]</td>\n",
       "      <td>[0.96760758907913, 0.22673031026252982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>train</th>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.812269</td>\n",
       "      <td>0.251958</td>\n",
       "      <td>[0.9634803825115108, 0.8368336025848142]</td>\n",
       "      <td>[0.9918168928499088, 0.5274949083503055]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.772411</td>\n",
       "      <td>0.542744</td>\n",
       "      <td>0.681547</td>\n",
       "      <td>[0.929081767663403, 0.15696465696465697]</td>\n",
       "      <td>[0.8123553910226747, 0.360381861575179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>train</th>\n",
       "      <td>0.952006</td>\n",
       "      <td>0.800895</td>\n",
       "      <td>0.248983</td>\n",
       "      <td>[0.9647736298649722, 0.7331518039482642]</td>\n",
       "      <td>[0.9841199108770509, 0.5483706720977597]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.900654</td>\n",
       "      <td>0.637232</td>\n",
       "      <td>0.47173</td>\n",
       "      <td>[0.9318232787620543, 0.4078014184397163]</td>\n",
       "      <td>[0.9613604812586766, 0.2744630071599045]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>train</th>\n",
       "      <td>0.956584</td>\n",
       "      <td>0.79405</td>\n",
       "      <td>0.282381</td>\n",
       "      <td>[0.9588501443170294, 0.8991097922848664]</td>\n",
       "      <td>[0.9958679359935183, 0.46283095723014256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.898756</td>\n",
       "      <td>0.606954</td>\n",
       "      <td>0.55602</td>\n",
       "      <td>[0.9265097690941385, 0.37130801687763715]</td>\n",
       "      <td>[0.9655252198056455, 0.2100238663484487]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>train</th>\n",
       "      <td>0.95118</td>\n",
       "      <td>0.795584</td>\n",
       "      <td>0.239462</td>\n",
       "      <td>[0.9637106369477274, 0.7310104529616724]</td>\n",
       "      <td>[0.9843629734656674, 0.5341140529531568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.916895</td>\n",
       "      <td>0.663059</td>\n",
       "      <td>0.445089</td>\n",
       "      <td>[0.9331715924128805, 0.5603864734299517]</td>\n",
       "      <td>[0.9789449329014345, 0.27684964200477324]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>train</th>\n",
       "      <td>0.95921</td>\n",
       "      <td>0.803399</td>\n",
       "      <td>0.245732</td>\n",
       "      <td>[0.959319526627219, 0.9562955254942768]</td>\n",
       "      <td>[0.998298561879684, 0.4679226069246436]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.90888</td>\n",
       "      <td>0.639117</td>\n",
       "      <td>0.468172</td>\n",
       "      <td>[0.9305002213368747, 0.47085201793721976]</td>\n",
       "      <td>[0.972697825080981, 0.25059665871121717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13</th>\n",
       "      <th>train</th>\n",
       "      <td>0.960899</td>\n",
       "      <td>0.813636</td>\n",
       "      <td>0.248401</td>\n",
       "      <td>[0.9608232955209917, 0.9628514056224899]</td>\n",
       "      <td>[0.9985011140368645, 0.48828920570264767]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.903396</td>\n",
       "      <td>0.650454</td>\n",
       "      <td>0.506134</td>\n",
       "      <td>[0.9339622641509434, 0.43252595155709345]</td>\n",
       "      <td>[0.962054604349838, 0.29832935560859186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
       "      <th>train</th>\n",
       "      <td>0.960299</td>\n",
       "      <td>0.809197</td>\n",
       "      <td>0.247192</td>\n",
       "      <td>[0.9600451730986409, 0.9670103092783505]</td>\n",
       "      <td>[0.9987036661940449, 0.4775967413441955]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.91795</td>\n",
       "      <td>0.661805</td>\n",
       "      <td>0.445093</td>\n",
       "      <td>[0.9326732673267327, 0.576530612244898]</td>\n",
       "      <td>[0.9807959278111985, 0.26968973747016706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">15</th>\n",
       "      <th>train</th>\n",
       "      <td>0.963151</td>\n",
       "      <td>0.830082</td>\n",
       "      <td>0.226865</td>\n",
       "      <td>[0.9639096567111598, 0.9455535390199638]</td>\n",
       "      <td>[0.9975693741138343, 0.5305498981670062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.915208</td>\n",
       "      <td>0.67175</td>\n",
       "      <td>0.405801</td>\n",
       "      <td>[0.9353620613060862, 0.5355648535564853]</td>\n",
       "      <td>[0.9743174456270245, 0.3054892601431981]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>train</th>\n",
       "      <td>0.958272</td>\n",
       "      <td>0.79645</td>\n",
       "      <td>0.247179</td>\n",
       "      <td>[0.958172983479106, 0.961038961038961]</td>\n",
       "      <td>[0.9985416244683006, 0.45213849287169044]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.920903</td>\n",
       "      <td>0.651729</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>[0.9302376280793547, 0.6428571428571429]</td>\n",
       "      <td>[0.9872744099953725, 0.23627684964200477]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17</th>\n",
       "      <th>train</th>\n",
       "      <td>0.961387</td>\n",
       "      <td>0.819008</td>\n",
       "      <td>0.238289</td>\n",
       "      <td>[0.96203125, 0.9456625357483317]</td>\n",
       "      <td>[0.9976909054081426, 0.505091649694501]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.919637</td>\n",
       "      <td>0.673692</td>\n",
       "      <td>0.444475</td>\n",
       "      <td>[0.9345093715545755, 0.5922330097087378]</td>\n",
       "      <td>[0.9805645534474781, 0.2911694510739857]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
       "      <th>train</th>\n",
       "      <td>0.961274</td>\n",
       "      <td>0.816938</td>\n",
       "      <td>0.239882</td>\n",
       "      <td>[0.9614859328052444, 0.9559686888454012]</td>\n",
       "      <td>[0.9981770305853758, 0.4974541751527495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.928707</td>\n",
       "      <td>0.679272</td>\n",
       "      <td>0.479077</td>\n",
       "      <td>[0.9330434782608695, 0.7872340425531915]</td>\n",
       "      <td>[0.993058769088385, 0.2649164677804296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">19</th>\n",
       "      <th>train</th>\n",
       "      <td>0.961687</td>\n",
       "      <td>0.819174</td>\n",
       "      <td>0.234928</td>\n",
       "      <td>[0.9617906486613067, 0.9591041869522883]</td>\n",
       "      <td>[0.998298561879684, 0.5015274949083504]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.920059</td>\n",
       "      <td>0.660189</td>\n",
       "      <td>0.474437</td>\n",
       "      <td>[0.9318729463307777, 0.6136363636363636]</td>\n",
       "      <td>[0.984266543267006, 0.2577565632458234]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1       nll  \\\n",
       "1  train  0.937559  0.757145  0.413565   \n",
       "   test   0.679182  0.496446  0.678223   \n",
       "2  train  0.954032  0.781115  0.305601   \n",
       "   test   0.910989  0.664824  0.417051   \n",
       "3  train  0.956959  0.787474  0.285249   \n",
       "   test   0.865007  0.607937  0.503948   \n",
       "4  train   0.95816  0.798594  0.275739   \n",
       "   test    0.92259  0.635217  0.431444   \n",
       "5  train   0.95467  0.790076   0.27285   \n",
       "   test   0.838009  0.579599  0.544394   \n",
       "6  train  0.954407  0.794968  0.264289   \n",
       "   test   0.909091  0.649548  0.412052   \n",
       "7  train  0.954632  0.768462  0.315977   \n",
       "   test    0.90213   0.61898  0.482983   \n",
       "8  train  0.957597  0.812269  0.251958   \n",
       "   test   0.772411  0.542744  0.681547   \n",
       "9  train  0.952006  0.800895  0.248983   \n",
       "   test   0.900654  0.637232   0.47173   \n",
       "10 train  0.956584   0.79405  0.282381   \n",
       "   test   0.898756  0.606954   0.55602   \n",
       "11 train   0.95118  0.795584  0.239462   \n",
       "   test   0.916895  0.663059  0.445089   \n",
       "12 train   0.95921  0.803399  0.245732   \n",
       "   test    0.90888  0.639117  0.468172   \n",
       "13 train  0.960899  0.813636  0.248401   \n",
       "   test   0.903396  0.650454  0.506134   \n",
       "14 train  0.960299  0.809197  0.247192   \n",
       "   test    0.91795  0.661805  0.445093   \n",
       "15 train  0.963151  0.830082  0.226865   \n",
       "   test   0.915208   0.67175  0.405801   \n",
       "16 train  0.958272   0.79645  0.247179   \n",
       "   test   0.920903  0.651729  0.420588   \n",
       "17 train  0.961387  0.819008  0.238289   \n",
       "   test   0.919637  0.673692  0.444475   \n",
       "18 train  0.961274  0.816938  0.239882   \n",
       "   test   0.928707  0.679272  0.479077   \n",
       "19 train  0.961687  0.819174  0.234928   \n",
       "   test   0.920059  0.660189  0.474437   \n",
       "\n",
       "                                          precision  \\\n",
       "1  train   [0.9616572414069707, 0.5874125874125874]   \n",
       "   test   [0.9276335877862596, 0.12414733969986358]   \n",
       "2  train   [0.9573099415204679, 0.8698698698698699]   \n",
       "   test    [0.9350736278447122, 0.4942084942084942]   \n",
       "3  train    [0.956835649406102, 0.9605411499436303]   \n",
       "   test    [0.9323626115547206, 0.2712215320910973]   \n",
       "4  train   [0.9588459741473291, 0.9398963730569948]   \n",
       "   test    [0.9273827534039334, 0.7280701754385965]   \n",
       "5  train   [0.9592347717225461, 0.8474264705882353]   \n",
       "   test     [0.929642166344294, 0.2115702479338843]   \n",
       "6  train   [0.9608466855168081, 0.8160337552742616]   \n",
       "   test   [0.9324294287619471, 0.47520661157024796]   \n",
       "7  train   [0.9539056457849961, 0.9784537389100126]   \n",
       "   test   [0.9280958721704394, 0.40425531914893614]   \n",
       "8  train   [0.9634803825115108, 0.8368336025848142]   \n",
       "   test    [0.929081767663403, 0.15696465696465697]   \n",
       "9  train   [0.9647736298649722, 0.7331518039482642]   \n",
       "   test    [0.9318232787620543, 0.4078014184397163]   \n",
       "10 train   [0.9588501443170294, 0.8991097922848664]   \n",
       "   test   [0.9265097690941385, 0.37130801687763715]   \n",
       "11 train   [0.9637106369477274, 0.7310104529616724]   \n",
       "   test    [0.9331715924128805, 0.5603864734299517]   \n",
       "12 train    [0.959319526627219, 0.9562955254942768]   \n",
       "   test   [0.9305002213368747, 0.47085201793721976]   \n",
       "13 train   [0.9608232955209917, 0.9628514056224899]   \n",
       "   test   [0.9339622641509434, 0.43252595155709345]   \n",
       "14 train   [0.9600451730986409, 0.9670103092783505]   \n",
       "   test     [0.9326732673267327, 0.576530612244898]   \n",
       "15 train   [0.9639096567111598, 0.9455535390199638]   \n",
       "   test    [0.9353620613060862, 0.5355648535564853]   \n",
       "16 train     [0.958172983479106, 0.961038961038961]   \n",
       "   test    [0.9302376280793547, 0.6428571428571429]   \n",
       "17 train           [0.96203125, 0.9456625357483317]   \n",
       "   test    [0.9345093715545755, 0.5922330097087378]   \n",
       "18 train   [0.9614859328052444, 0.9559686888454012]   \n",
       "   test    [0.9330434782608695, 0.7872340425531915]   \n",
       "19 train   [0.9617906486613067, 0.9591041869522883]   \n",
       "   test    [0.9318729463307777, 0.6136363636363636]   \n",
       "\n",
       "                                             recall  \n",
       "1  train   [0.9713186145432449, 0.5132382892057027]  \n",
       "   test    [0.7029153169828783, 0.4343675417661098]  \n",
       "2  train   [0.9947336439133077, 0.4424643584521385]  \n",
       "   test    [0.9696899583526145, 0.3054892601431981]  \n",
       "3  train  [0.9985821348997367, 0.43380855397148677]  \n",
       "   test    [0.9185562239703841, 0.3126491646778043]  \n",
       "4  train  [0.9976503949767065, 0.46181262729124234]  \n",
       "   test   [0.9928273947246645, 0.19809069212410502]  \n",
       "5  train   [0.9932752683816083, 0.4694501018329939]  \n",
       "   test    [0.8896344285053216, 0.3054892601431981]  \n",
       "6  train   [0.9911687259469313, 0.4923625254582485]  \n",
       "   test    [0.9706154558074965, 0.2744630071599045]  \n",
       "7  train  [0.9993113226655864, 0.39307535641547864]  \n",
       "   test     [0.96760758907913, 0.22673031026252982]  \n",
       "8  train   [0.9918168928499088, 0.5274949083503055]  \n",
       "   test     [0.8123553910226747, 0.360381861575179]  \n",
       "9  train   [0.9841199108770509, 0.5483706720977597]  \n",
       "   test    [0.9613604812586766, 0.2744630071599045]  \n",
       "10 train  [0.9958679359935183, 0.46283095723014256]  \n",
       "   test    [0.9655252198056455, 0.2100238663484487]  \n",
       "11 train   [0.9843629734656674, 0.5341140529531568]  \n",
       "   test   [0.9789449329014345, 0.27684964200477324]  \n",
       "12 train    [0.998298561879684, 0.4679226069246436]  \n",
       "   test    [0.972697825080981, 0.25059665871121717]  \n",
       "13 train  [0.9985011140368645, 0.48828920570264767]  \n",
       "   test    [0.962054604349838, 0.29832935560859186]  \n",
       "14 train   [0.9987036661940449, 0.4775967413441955]  \n",
       "   test   [0.9807959278111985, 0.26968973747016706]  \n",
       "15 train   [0.9975693741138343, 0.5305498981670062]  \n",
       "   test    [0.9743174456270245, 0.3054892601431981]  \n",
       "16 train  [0.9985416244683006, 0.45213849287169044]  \n",
       "   test   [0.9872744099953725, 0.23627684964200477]  \n",
       "17 train    [0.9976909054081426, 0.505091649694501]  \n",
       "   test    [0.9805645534474781, 0.2911694510739857]  \n",
       "18 train   [0.9981770305853758, 0.4974541751527495]  \n",
       "   test     [0.993058769088385, 0.2649164677804296]  \n",
       "19 train    [0.998298561879684, 0.5015274949083504]  \n",
       "   test     [0.984266543267006, 0.2577565632458234]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in trainer.epoch_state.items() for innerKey, values in innerDict.items()}\n",
    "df = pd.DataFrame(reform).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
