{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_classification.datasets import FolderOfFrameFoldersDataset, FrameWindowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = \"cpu\"  # we don't need cuda for this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = Path(\"/Users/ludovica/Documents/Insight/data\")\n",
    "DATA_ROOT = Path(ROOT/\"frame_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ludovica/Documents/Insight/data/frame_data')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    torchvision.transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomVerticalFlip(p=0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FolderOfFrameFoldersDataset(DATA_ROOT/'train', \n",
    "                                       transform=train_transforms, \n",
    "                                       base_class=FrameWindowDataset,\n",
    "                                       window_size=2,\n",
    "                                       overlapping=True,)\n",
    "valid_ds = FolderOfFrameFoldersDataset(DATA_ROOT/'validation', \n",
    "                                       transform=valid_transforms, \n",
    "                                       base_class=FrameWindowDataset,\n",
    "                                       window_size=2,\n",
    "                                       overlapping=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_prev, x_cur), label = train_ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FrameToFrameModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is [B, T, C, H, W]\n",
    "        x = x.transpose(0, 1)\n",
    "        x_prev, x_cur = x\n",
    "        with torch.no_grad():\n",
    "            loss = F.mse_loss(x_prev, x_cur, reduction='none').mean([1, 2, 3])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = FrameToFrameModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/99 [00:05<08:49,  5.40s/it]\u001b[A\n",
      "  2%|▏         | 2/99 [00:06<06:24,  3.96s/it]\u001b[A\n",
      "  3%|▎         | 3/99 [00:06<04:43,  2.96s/it]\u001b[A\n",
      "  4%|▍         | 4/99 [00:07<03:36,  2.28s/it]\u001b[A\n",
      "  5%|▌         | 5/99 [00:08<03:15,  2.08s/it]\u001b[A\n",
      "  6%|▌         | 6/99 [00:09<02:30,  1.61s/it]\u001b[A\n",
      "  7%|▋         | 7/99 [00:10<01:58,  1.29s/it]\u001b[A\n",
      "  8%|▊         | 8/99 [00:10<01:37,  1.07s/it]\u001b[A\n",
      "  9%|▉         | 9/99 [00:11<01:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 10/99 [00:12<01:24,  1.06it/s]\u001b[A\n",
      " 11%|█         | 11/99 [00:12<01:12,  1.21it/s]\u001b[A\n",
      " 12%|█▏        | 12/99 [00:13<01:05,  1.34it/s]\u001b[A\n",
      " 13%|█▎        | 13/99 [00:15<01:26,  1.00s/it]\u001b[A\n",
      " 14%|█▍        | 14/99 [00:15<01:13,  1.16it/s]\u001b[A\n",
      " 15%|█▌        | 15/99 [00:16<01:04,  1.31it/s]\u001b[A\n",
      " 16%|█▌        | 16/99 [00:16<00:57,  1.44it/s]\u001b[A\n",
      " 17%|█▋        | 17/99 [00:18<01:19,  1.03it/s]\u001b[A\n",
      " 18%|█▊        | 18/99 [00:18<01:07,  1.19it/s]\u001b[A\n",
      " 19%|█▉        | 19/99 [00:19<01:00,  1.32it/s]\u001b[A\n",
      " 20%|██        | 20/99 [00:19<00:54,  1.44it/s]\u001b[A\n",
      " 21%|██        | 21/99 [00:21<01:11,  1.10it/s]\u001b[A\n",
      " 22%|██▏       | 22/99 [00:21<01:01,  1.26it/s]\u001b[A\n",
      " 23%|██▎       | 23/99 [00:22<00:54,  1.39it/s]\u001b[A\n",
      " 24%|██▍       | 24/99 [00:22<00:50,  1.49it/s]\u001b[A\n",
      " 25%|██▌       | 25/99 [00:24<01:09,  1.07it/s]\u001b[A\n",
      " 26%|██▋       | 26/99 [00:25<00:59,  1.22it/s]\u001b[A\n",
      " 27%|██▋       | 27/99 [00:25<00:52,  1.36it/s]\u001b[A\n",
      " 28%|██▊       | 28/99 [00:26<00:47,  1.48it/s]\u001b[A\n",
      " 29%|██▉       | 29/99 [00:27<01:05,  1.06it/s]\u001b[A\n",
      " 30%|███       | 30/99 [00:28<00:56,  1.21it/s]\u001b[A\n",
      " 31%|███▏      | 31/99 [00:28<00:50,  1.33it/s]\u001b[A\n",
      " 32%|███▏      | 32/99 [00:29<00:46,  1.45it/s]\u001b[A\n",
      " 33%|███▎      | 33/99 [00:30<01:00,  1.08it/s]\u001b[A\n",
      " 34%|███▍      | 34/99 [00:31<00:52,  1.24it/s]\u001b[A\n",
      " 35%|███▌      | 35/99 [00:31<00:46,  1.38it/s]\u001b[A\n",
      " 36%|███▋      | 36/99 [00:32<00:42,  1.50it/s]\u001b[A\n",
      " 37%|███▋      | 37/99 [00:33<00:52,  1.19it/s]\u001b[A\n",
      " 38%|███▊      | 38/99 [00:34<00:46,  1.32it/s]\u001b[A\n",
      " 39%|███▉      | 39/99 [00:34<00:41,  1.44it/s]\u001b[A\n",
      " 40%|████      | 40/99 [00:35<00:37,  1.57it/s]\u001b[A\n",
      " 41%|████▏     | 41/99 [00:37<00:57,  1.01it/s]\u001b[A\n",
      " 42%|████▏     | 42/99 [00:37<00:48,  1.17it/s]\u001b[A\n",
      " 43%|████▎     | 43/99 [00:38<00:42,  1.32it/s]\u001b[A\n",
      " 44%|████▍     | 44/99 [00:38<00:38,  1.43it/s]\u001b[A\n",
      " 45%|████▌     | 45/99 [00:40<00:55,  1.02s/it]\u001b[A\n",
      " 46%|████▋     | 46/99 [00:41<00:46,  1.14it/s]\u001b[A\n",
      " 47%|████▋     | 47/99 [00:41<00:40,  1.30it/s]\u001b[A\n",
      " 48%|████▊     | 48/99 [00:42<00:35,  1.43it/s]\u001b[A\n",
      " 49%|████▉     | 49/99 [00:43<00:49,  1.02it/s]\u001b[A\n",
      " 51%|█████     | 50/99 [00:44<00:41,  1.19it/s]\u001b[A\n",
      " 52%|█████▏    | 51/99 [00:44<00:35,  1.34it/s]\u001b[A\n",
      " 53%|█████▎    | 52/99 [00:45<00:32,  1.45it/s]\u001b[A\n",
      " 54%|█████▎    | 53/99 [00:46<00:39,  1.16it/s]\u001b[A\n",
      " 55%|█████▍    | 54/99 [00:47<00:34,  1.31it/s]\u001b[A\n",
      " 56%|█████▌    | 55/99 [00:47<00:30,  1.43it/s]\u001b[A\n",
      " 57%|█████▋    | 56/99 [00:48<00:28,  1.52it/s]\u001b[A\n",
      " 58%|█████▊    | 57/99 [00:49<00:33,  1.24it/s]\u001b[A\n",
      " 59%|█████▊    | 58/99 [00:49<00:29,  1.37it/s]\u001b[A\n",
      " 60%|█████▉    | 59/99 [00:50<00:27,  1.48it/s]\u001b[A\n",
      " 61%|██████    | 60/99 [00:51<00:25,  1.56it/s]\u001b[A\n",
      " 62%|██████▏   | 61/99 [00:52<00:32,  1.17it/s]\u001b[A\n",
      " 63%|██████▎   | 62/99 [00:52<00:28,  1.31it/s]\u001b[A\n",
      " 64%|██████▎   | 63/99 [00:53<00:24,  1.44it/s]\u001b[A\n",
      " 65%|██████▍   | 64/99 [00:54<00:22,  1.55it/s]\u001b[A\n",
      " 66%|██████▌   | 65/99 [00:55<00:28,  1.18it/s]\u001b[A\n",
      " 67%|██████▋   | 66/99 [00:55<00:24,  1.33it/s]\u001b[A\n",
      " 68%|██████▊   | 67/99 [00:56<00:22,  1.45it/s]\u001b[A\n",
      " 69%|██████▊   | 68/99 [00:56<00:20,  1.55it/s]\u001b[A\n",
      " 70%|██████▉   | 69/99 [00:58<00:24,  1.21it/s]\u001b[A\n",
      " 71%|███████   | 70/99 [00:58<00:21,  1.36it/s]\u001b[A\n",
      " 72%|███████▏  | 71/99 [00:59<00:19,  1.47it/s]\u001b[A\n",
      " 73%|███████▎  | 72/99 [00:59<00:17,  1.59it/s]\u001b[A\n",
      " 74%|███████▎  | 73/99 [01:01<00:21,  1.22it/s]\u001b[A\n",
      " 75%|███████▍  | 74/99 [01:01<00:18,  1.36it/s]\u001b[A\n",
      " 76%|███████▌  | 75/99 [01:02<00:16,  1.48it/s]\u001b[A\n",
      " 77%|███████▋  | 76/99 [01:02<00:14,  1.57it/s]\u001b[A\n",
      " 78%|███████▊  | 77/99 [01:04<00:19,  1.14it/s]\u001b[A\n",
      " 79%|███████▉  | 78/99 [01:04<00:16,  1.29it/s]\u001b[A\n",
      " 80%|███████▉  | 79/99 [01:05<00:14,  1.42it/s]\u001b[A\n",
      " 81%|████████  | 80/99 [01:05<00:12,  1.54it/s]\u001b[A\n",
      " 82%|████████▏ | 81/99 [01:07<00:15,  1.14it/s]\u001b[A\n",
      " 83%|████████▎ | 82/99 [01:07<00:13,  1.28it/s]\u001b[A\n",
      " 84%|████████▍ | 83/99 [01:08<00:11,  1.41it/s]\u001b[A\n",
      " 85%|████████▍ | 84/99 [01:08<00:09,  1.54it/s]\u001b[A\n",
      " 86%|████████▌ | 85/99 [01:10<00:12,  1.11it/s]\u001b[A\n",
      " 87%|████████▋ | 86/99 [01:10<00:10,  1.26it/s]\u001b[A\n",
      " 88%|████████▊ | 87/99 [01:11<00:08,  1.39it/s]\u001b[A\n",
      " 89%|████████▉ | 88/99 [01:11<00:07,  1.52it/s]\u001b[A\n",
      " 90%|████████▉ | 89/99 [01:13<00:08,  1.15it/s]\u001b[A\n",
      " 91%|█████████ | 90/99 [01:13<00:06,  1.30it/s]\u001b[A\n",
      " 92%|█████████▏| 91/99 [01:14<00:05,  1.43it/s]\u001b[A\n",
      " 93%|█████████▎| 92/99 [01:14<00:04,  1.57it/s]\u001b[A\n",
      " 94%|█████████▍| 93/99 [01:16<00:05,  1.09it/s]\u001b[A\n",
      " 95%|█████████▍| 94/99 [01:16<00:03,  1.31it/s]\u001b[A\n",
      " 96%|█████████▌| 95/99 [01:17<00:02,  1.50it/s]\u001b[A\n",
      " 97%|█████████▋| 96/99 [01:17<00:01,  1.65it/s]\u001b[A\n",
      " 98%|█████████▊| 97/99 [01:18<00:01,  1.31it/s]\u001b[A\n",
      " 99%|█████████▉| 98/99 [01:19<00:00,  1.61it/s]\u001b[A\n",
      "100%|██████████| 99/99 [01:19<00:00,  1.97it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=48, shuffle=False, num_workers=4)\n",
    "scores = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(tqdm(valid_loader)):\n",
    "        batch_scores = scorer(x).tolist()\n",
    "        scores.extend((s for s in batch_scores))\n",
    "        y_true.extend((s for s in y))\n",
    "        \n",
    "scores = np.array(scores)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00032781, 0.00032003, 0.00034775, ..., 0.00034765, 0.00034415,\n",
       "       0.00033726])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"frametoframe_mse_scores.json\", 'w') as fout:\n",
    "    json.dump(scores.tolist(), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean = scores.mean()\n",
    "mse_std = scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnomalyDetectionModel(nn.Module):\n",
    "    def __init__(self, mean, std, alpha):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (x > self.mean + self.alpha * self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = AnomalyDetectionModel(mse_mean, mse_std, 1.2)  # alpha tweaked to predict about 7% of positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred == True].shape    # Used this to tweak alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.906333</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.904553</td>\n",
       "      <td>4327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053801</td>\n",
       "      <td>0.052752</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.829541</td>\n",
       "      <td>0.829541</td>\n",
       "      <td>0.829541</td>\n",
       "      <td>0.829541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.480067</td>\n",
       "      <td>0.480436</td>\n",
       "      <td>0.479723</td>\n",
       "      <td>4746.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.831068</td>\n",
       "      <td>0.832605</td>\n",
       "      <td>0.829541</td>\n",
       "      <td>4746.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall      support\n",
       "0             0.906333   0.908121  0.904553  4327.000000\n",
       "1             0.053801   0.052752  0.054893   419.000000\n",
       "accuracy      0.829541   0.829541  0.829541     0.829541\n",
       "macro avg     0.480067   0.480436  0.479723  4746.000000\n",
       "weighted avg  0.831068   0.832605  0.829541  4746.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaaand our results suck :| :|\n",
    "\n",
    "Actually, they are not that bad: the frame to frame detector can only detect anomalies from the status quo, so it should only detect when we toggle from finding an anomaly to normal, and vice versa. Let's use this to get our real y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toggle_predictions(spikes_pred):\n",
    "    cur = False\n",
    "    toggled = []\n",
    "    for v in spikes_pred:\n",
    "        if v:\n",
    "            cur = not cur\n",
    "        toggled.append(cur)\n",
    "    return toggled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_toggled = toggle_predictions(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876689</td>\n",
       "      <td>0.926183</td>\n",
       "      <td>0.832216</td>\n",
       "      <td>4327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206735</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.315036</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.786557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.541712</td>\n",
       "      <td>0.540015</td>\n",
       "      <td>0.573626</td>\n",
       "      <td>4746.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.817542</td>\n",
       "      <td>0.857997</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>4746.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall      support\n",
       "0             0.876689   0.926183  0.832216  4327.000000\n",
       "1             0.206735   0.153846  0.315036   419.000000\n",
       "accuracy      0.786557   0.786557  0.786557     0.786557\n",
       "macro avg     0.541712   0.540015  0.573626  4746.000000\n",
       "weighted avg  0.817542   0.857997  0.786557  4746.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "pd.DataFrame(classification_report(y_true, y_pred_toggled, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While still not amazing, we do get to a f1-score of **0.20** through this purely unsupervised method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
