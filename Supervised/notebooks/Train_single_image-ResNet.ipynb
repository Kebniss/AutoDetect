{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from video_classification.datasets import FolderOfFrameFoldersDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = Path(\"/home/ubuntu/SupervisedVideoClassification\")\n",
    "DATA_ROOT = Path(ROOT/\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    torchvision.transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomVerticalFlip(p=0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ds = FolderOfFrameFoldersDataset(DATA_ROOT/'train', transform=train_transforms)\n",
    "valid_ds = FolderOfFrameFoldersDataset(DATA_ROOT/'validation', transform=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FolderOfFrameFoldersDataset with 26711 samples.\n",
       "\tOverall data distribution: {'negative': 24747, 'positive': 1964}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FolderOfFrameFoldersDataset with 4751 samples.\n",
       "\tOverall data distribution: {'negative': 4332, 'positive': 419}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.models import resnet101\n",
    "from video_classification.models.mlp import MLP\n",
    "\n",
    "\n",
    "class SingleImageResNetModel(nn.Module):\n",
    "    def __init__(self, mlp_sizes=[768, 128, 2]):\n",
    "        super().__init__()\n",
    "        resnet = resnet101(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "\n",
    "        self.clf = MLP(2048, mlp_sizes)\n",
    "        self.freeze_resnet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x).squeeze()\n",
    "        x = self.clf(x)\n",
    "        return x\n",
    "\n",
    "    def freeze_resnet(self):\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_resnet(self):\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SingleImageResNetModel(mlp_sizes=[1024, 256, 2])\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from video_classification.trainer import Trainer\n",
    "\n",
    "classes_weights = torch.Tensor([0.3, 1.0]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(train_ds, \n",
    "                  valid_ds, \n",
    "                  model, \n",
    "                  criterion,\n",
    "                  \"single_frame_resnet\",\n",
    "                  str(ROOT/'checkpoints'),\n",
    "                  device=device,\n",
    "                  amp_opt_level=\"O1\",\n",
    "                  cycle_mult=0.9,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1: Avg accuracy: 0.95 |Precision: 0.95, 0.88 |Recall: 1.00, 0.35 | F1: 0.74 | Avg loss: 0.34\n",
      "Validation Results - Epoch: 1: Avg accuracy: 0.89 |Precision: 0.93, 0.37 |Recall: 0.95, 0.30 | F1: 0.64 | Avg loss: 0.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 2: Avg accuracy: 0.88 |Precision: 0.98, 0.34 |Recall: 0.89, 0.74 | F1: 0.70 | Avg loss: 0.34\n",
      "Validation Results - Epoch: 2: Avg accuracy: 0.79 |Precision: 0.94, 0.21 |Recall: 0.82, 0.50 | F1: 0.59 | Avg loss: 0.52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 3: Avg accuracy: 0.85 |Precision: 0.98, 0.29 |Recall: 0.86, 0.73 | F1: 0.67 | Avg loss: 0.36\n",
      "Validation Results - Epoch: 3: Avg accuracy: 0.75 |Precision: 0.94, 0.17 |Recall: 0.78, 0.47 | F1: 0.55 | Avg loss: 0.55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 4: Avg accuracy: 0.95 |Precision: 0.97, 0.74 |Recall: 0.98, 0.57 | F1: 0.81 | Avg loss: 0.24\n",
      "Validation Results - Epoch: 4: Avg accuracy: 0.89 |Precision: 0.94, 0.37 |Recall: 0.94, 0.33 | F1: 0.64 | Avg loss: 0.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 5: Avg accuracy: 0.94 |Precision: 0.98, 0.58 |Recall: 0.96, 0.70 | F1: 0.80 | Avg loss: 0.23\n",
      "Validation Results - Epoch: 5: Avg accuracy: 0.84 |Precision: 0.94, 0.27 |Recall: 0.88, 0.47 | F1: 0.63 | Avg loss: 0.47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 6: Avg accuracy: 0.95 |Precision: 0.97, 0.64 |Recall: 0.97, 0.65 | F1: 0.81 | Avg loss: 0.24\n",
      "Validation Results - Epoch: 6: Avg accuracy: 0.89 |Precision: 0.94, 0.39 |Recall: 0.94, 0.37 | F1: 0.66 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 7: Avg accuracy: 0.96 |Precision: 0.96, 0.93 |Recall: 1.00, 0.49 | F1: 0.81 | Avg loss: 0.25\n",
      "Validation Results - Epoch: 7: Avg accuracy: 0.94 |Precision: 0.94, 0.95 |Recall: 1.00, 0.29 | F1: 0.71 | Avg loss: 0.48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 8: Avg accuracy: 0.93 |Precision: 0.98, 0.54 |Recall: 0.95, 0.78 | F1: 0.80 | Avg loss: 0.22\n",
      "Validation Results - Epoch: 8: Avg accuracy: 0.85 |Precision: 0.95, 0.30 |Recall: 0.89, 0.49 | F1: 0.65 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 9: Avg accuracy: 0.95 |Precision: 0.98, 0.68 |Recall: 0.97, 0.72 | F1: 0.84 | Avg loss: 0.20\n",
      "Validation Results - Epoch: 9: Avg accuracy: 0.91 |Precision: 0.94, 0.47 |Recall: 0.96, 0.34 | F1: 0.67 | Avg loss: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 10: Avg accuracy: 0.95 |Precision: 0.98, 0.62 |Recall: 0.96, 0.77 | F1: 0.83 | Avg loss: 0.19\n",
      "Validation Results - Epoch: 10: Avg accuracy: 0.90 |Precision: 0.94, 0.41 |Recall: 0.95, 0.39 | F1: 0.67 | Avg loss: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 11: Avg accuracy: 0.96 |Precision: 0.97, 0.83 |Recall: 0.99, 0.61 | F1: 0.84 | Avg loss: 0.21\n",
      "Validation Results - Epoch: 11: Avg accuracy: 0.93 |Precision: 0.94, 0.69 |Recall: 0.98, 0.36 | F1: 0.72 | Avg loss: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 12: Avg accuracy: 0.96 |Precision: 0.98, 0.77 |Recall: 0.98, 0.69 | F1: 0.85 | Avg loss: 0.18\n",
      "Validation Results - Epoch: 12: Avg accuracy: 0.93 |Precision: 0.95, 0.66 |Recall: 0.98, 0.45 | F1: 0.75 | Avg loss: 0.37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 13: Avg accuracy: 0.96 |Precision: 0.98, 0.76 |Recall: 0.98, 0.74 | F1: 0.86 | Avg loss: 0.18\n",
      "Validation Results - Epoch: 13: Avg accuracy: 0.91 |Precision: 0.94, 0.51 |Recall: 0.96, 0.39 | F1: 0.70 | Avg loss: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 14: Avg accuracy: 0.95 |Precision: 0.98, 0.63 |Recall: 0.96, 0.78 | F1: 0.83 | Avg loss: 0.19\n",
      "Validation Results - Epoch: 14: Avg accuracy: 0.88 |Precision: 0.95, 0.39 |Recall: 0.92, 0.55 | F1: 0.70 | Avg loss: 0.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 15: Avg accuracy: 0.96 |Precision: 0.98, 0.68 |Recall: 0.97, 0.79 | F1: 0.85 | Avg loss: 0.17\n",
      "Validation Results - Epoch: 15: Avg accuracy: 0.91 |Precision: 0.94, 0.51 |Recall: 0.97, 0.37 | F1: 0.69 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 16: Avg accuracy: 0.96 |Precision: 0.98, 0.72 |Recall: 0.98, 0.77 | F1: 0.86 | Avg loss: 0.16\n",
      "Validation Results - Epoch: 16: Avg accuracy: 0.91 |Precision: 0.95, 0.49 |Recall: 0.95, 0.47 | F1: 0.71 | Avg loss: 0.40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 17: Avg accuracy: 0.96 |Precision: 0.98, 0.76 |Recall: 0.98, 0.76 | F1: 0.87 | Avg loss: 0.17\n",
      "Validation Results - Epoch: 17: Avg accuracy: 0.91 |Precision: 0.94, 0.52 |Recall: 0.97, 0.36 | F1: 0.69 | Avg loss: 0.47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 18: Avg accuracy: 0.97 |Precision: 0.98, 0.80 |Recall: 0.99, 0.71 | F1: 0.87 | Avg loss: 0.17\n",
      "Validation Results - Epoch: 18: Avg accuracy: 0.92 |Precision: 0.94, 0.59 |Recall: 0.97, 0.38 | F1: 0.71 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 19: Avg accuracy: 0.96 |Precision: 0.98, 0.72 |Recall: 0.98, 0.80 | F1: 0.87 | Avg loss: 0.15\n",
      "Validation Results - Epoch: 19: Avg accuracy: 0.91 |Precision: 0.94, 0.51 |Recall: 0.96, 0.41 | F1: 0.70 | Avg loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 20: Avg accuracy: 0.97 |Precision: 0.98, 0.79 |Recall: 0.98, 0.76 | F1: 0.88 | Avg loss: 0.16\n",
      "Validation Results - Epoch: 20: Avg accuracy: 0.93 |Precision: 0.95, 0.72 |Recall: 0.98, 0.42 | F1: 0.75 | Avg loss: 0.44\n"
     ]
    }
   ],
   "source": [
    "trainer.train(lr=1e-3, \n",
    "              batch_size=128, \n",
    "              n_epochs=20,\n",
    "              gradient_accumulation_steps=2,\n",
    "              num_workers=8,\n",
    "              max_gradient_norm=2.0,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>nll</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>0.948935</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>[0.9510435554183866, 0.879746835443038]</td>\n",
       "      <td>[0.9961611508465673, 0.35386965376782076]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.894338</td>\n",
       "      <td>0.636654</td>\n",
       "      <td>0.460383</td>\n",
       "      <td>[0.9332579185520362, 0.37462235649546827]</td>\n",
       "      <td>[0.9522160664819944, 0.29594272076372313]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>0.87698</td>\n",
       "      <td>0.699279</td>\n",
       "      <td>0.336004</td>\n",
       "      <td>[0.9769747077388096, 0.3431419079259611]</td>\n",
       "      <td>[0.8881480583505071, 0.7362525458248472]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.790149</td>\n",
       "      <td>0.586061</td>\n",
       "      <td>0.521678</td>\n",
       "      <td>[0.9440745672436751, 0.20983935742971888]</td>\n",
       "      <td>[0.8183287165281625, 0.4988066825775656]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>0.849163</td>\n",
       "      <td>0.665361</td>\n",
       "      <td>0.361623</td>\n",
       "      <td>[0.9760569852941177, 0.29145627146031106]</td>\n",
       "      <td>[0.8582454438921889, 0.734725050916497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.751842</td>\n",
       "      <td>0.551804</td>\n",
       "      <td>0.553447</td>\n",
       "      <td>[0.9387698302254384, 0.17184801381692574]</td>\n",
       "      <td>[0.778624192059095, 0.47494033412887826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>0.95354</td>\n",
       "      <td>0.808503</td>\n",
       "      <td>0.244142</td>\n",
       "      <td>[0.9662038873462911, 0.7408394403730846]</td>\n",
       "      <td>[0.9842809229401543, 0.5661914460285132]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.890339</td>\n",
       "      <td>0.644035</td>\n",
       "      <td>0.435605</td>\n",
       "      <td>[0.9359414321665522, 0.36578947368421055]</td>\n",
       "      <td>[0.9443674976915974, 0.3317422434367542]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>0.940998</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.233504</td>\n",
       "      <td>[0.9761229605885012, 0.5815811606391926]</td>\n",
       "      <td>[0.9597931062350992, 0.7041751527494908]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.840244</td>\n",
       "      <td>0.625963</td>\n",
       "      <td>0.466015</td>\n",
       "      <td>[0.9449564134495642, 0.26902173913043476]</td>\n",
       "      <td>[0.8758079409048938, 0.47255369928400953]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>train</th>\n",
       "      <td>0.947699</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.243121</td>\n",
       "      <td>[0.9722896440129449, 0.6423907584128579]</td>\n",
       "      <td>[0.9712288358184831, 0.6512219959266803]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.660857</td>\n",
       "      <td>0.45323</td>\n",
       "      <td>[0.9397008055235904, 0.3866995073891626]</td>\n",
       "      <td>[0.9425207756232687, 0.3747016706443914]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>train</th>\n",
       "      <td>0.959904</td>\n",
       "      <td>0.811412</td>\n",
       "      <td>0.251877</td>\n",
       "      <td>[0.9612327592924491, 0.9272727272727272]</td>\n",
       "      <td>[0.9969289206772538, 0.49338085539714865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.706117</td>\n",
       "      <td>0.477989</td>\n",
       "      <td>[0.9357560025957171, 0.953125]</td>\n",
       "      <td>[0.9986149584487535, 0.2911694510739857]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>train</th>\n",
       "      <td>0.93411</td>\n",
       "      <td>0.800068</td>\n",
       "      <td>0.220587</td>\n",
       "      <td>[0.982211034193413, 0.5354659248956884]</td>\n",
       "      <td>[0.9460136582211985, 0.7841140529531568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.853505</td>\n",
       "      <td>0.645018</td>\n",
       "      <td>0.450793</td>\n",
       "      <td>[0.9477832512315271, 0.2995658465991317]</td>\n",
       "      <td>[0.8882733148661126, 0.49403341288782815]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>train</th>\n",
       "      <td>0.954738</td>\n",
       "      <td>0.837576</td>\n",
       "      <td>0.197617</td>\n",
       "      <td>[0.9774442190669371, 0.683163512857836]</td>\n",
       "      <td>[0.973612963187457, 0.7169042769857433]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.90844</td>\n",
       "      <td>0.673566</td>\n",
       "      <td>0.432827</td>\n",
       "      <td>[0.9379635873229939, 0.4735099337748344]</td>\n",
       "      <td>[0.9632963988919667, 0.3412887828162291]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>train</th>\n",
       "      <td>0.947999</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>[0.9816479709666777, 0.6167275680064962]</td>\n",
       "      <td>[0.9618539620964157, 0.7734215885947047]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.896443</td>\n",
       "      <td>0.672389</td>\n",
       "      <td>0.433336</td>\n",
       "      <td>[0.9415823367065317, 0.4094292803970223]</td>\n",
       "      <td>[0.9450600184672207, 0.3937947494033413]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>train</th>\n",
       "      <td>0.962562</td>\n",
       "      <td>0.843118</td>\n",
       "      <td>0.209256</td>\n",
       "      <td>[0.9698468600371968, 0.8347222222222223]</td>\n",
       "      <td>[0.9903826726471896, 0.6120162932790224]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.929489</td>\n",
       "      <td>0.71733</td>\n",
       "      <td>0.431287</td>\n",
       "      <td>[0.940683572216097, 0.6944444444444444]</td>\n",
       "      <td>[0.9847645429362881, 0.35799522673031026]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>train</th>\n",
       "      <td>0.961589</td>\n",
       "      <td>0.851849</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>[0.9753135895483509, 0.7667804323094426]</td>\n",
       "      <td>[0.9834323352325535, 0.6863543788187373]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.931172</td>\n",
       "      <td>0.749499</td>\n",
       "      <td>0.366148</td>\n",
       "      <td>[0.948488241881299, 0.6608391608391608]</td>\n",
       "      <td>[0.9776084949215144, 0.4510739856801909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13</th>\n",
       "      <th>train</th>\n",
       "      <td>0.963386</td>\n",
       "      <td>0.864034</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>[0.9792716860910594, 0.7575757575757576]</td>\n",
       "      <td>[0.9812502525558654, 0.7382892057026477]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.913071</td>\n",
       "      <td>0.698497</td>\n",
       "      <td>0.433779</td>\n",
       "      <td>[0.9426248023492206, 0.5092592592592593]</td>\n",
       "      <td>[0.9632963988919667, 0.3937947494033413]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
       "      <th>train</th>\n",
       "      <td>0.949459</td>\n",
       "      <td>0.833029</td>\n",
       "      <td>0.187926</td>\n",
       "      <td>[0.9820346944661914, 0.6257166257166257]</td>\n",
       "      <td>[0.9630662302501314, 0.7780040733197556]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.883393</td>\n",
       "      <td>0.695248</td>\n",
       "      <td>0.38541</td>\n",
       "      <td>[0.9549614643545279, 0.38731218697829717]</td>\n",
       "      <td>[0.9152816251154201, 0.5536992840095465]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">15</th>\n",
       "      <th>train</th>\n",
       "      <td>0.956797</td>\n",
       "      <td>0.852438</td>\n",
       "      <td>0.165108</td>\n",
       "      <td>[0.9829287264093012, 0.6773204903677759]</td>\n",
       "      <td>[0.9702186123570534, 0.7876782077393075]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.91265</td>\n",
       "      <td>0.688575</td>\n",
       "      <td>0.45094</td>\n",
       "      <td>[0.9402112834344797, 0.5066225165562914]</td>\n",
       "      <td>[0.9656048014773777, 0.36515513126491644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>train</th>\n",
       "      <td>0.961589</td>\n",
       "      <td>0.863005</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>[0.9816837915769808, 0.7246168582375478]</td>\n",
       "      <td>[0.9767648603871176, 0.7703665987780041]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.909282</td>\n",
       "      <td>0.712691</td>\n",
       "      <td>0.397953</td>\n",
       "      <td>[0.9484939066452058, 0.48507462686567165]</td>\n",
       "      <td>[0.9522160664819944, 0.46539379474940334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17</th>\n",
       "      <th>train</th>\n",
       "      <td>0.964621</td>\n",
       "      <td>0.870194</td>\n",
       "      <td>0.170055</td>\n",
       "      <td>[0.9809262102966136, 0.7592875318066158]</td>\n",
       "      <td>[0.9808865721097507, 0.7596741344195519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.914123</td>\n",
       "      <td>0.690275</td>\n",
       "      <td>0.474155</td>\n",
       "      <td>[0.9401076716016151, 0.5187713310580204]</td>\n",
       "      <td>[0.9674515235457064, 0.3627684964200477]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
       "      <th>train</th>\n",
       "      <td>0.96552</td>\n",
       "      <td>0.866446</td>\n",
       "      <td>0.171757</td>\n",
       "      <td>[0.9770925110132158, 0.7995404939689833]</td>\n",
       "      <td>[0.9858972804784418, 0.7087576374745418]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.708548</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>[0.9417670682730924, 0.587360594795539]</td>\n",
       "      <td>[0.974376731301939, 0.37708830548926014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">19</th>\n",
       "      <th>train</th>\n",
       "      <td>0.962675</td>\n",
       "      <td>0.869906</td>\n",
       "      <td>0.149125</td>\n",
       "      <td>[0.9842985318107668, 0.7206754906435417]</td>\n",
       "      <td>[0.9752697296642017, 0.8039714867617108]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.913702</td>\n",
       "      <td>0.703243</td>\n",
       "      <td>0.454537</td>\n",
       "      <td>[0.9436651583710407, 0.513595166163142]</td>\n",
       "      <td>[0.9628347183748845, 0.40572792362768495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th>train</th>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.879744</td>\n",
       "      <td>0.155042</td>\n",
       "      <td>[0.981031774797632, 0.7941489361702128]</td>\n",
       "      <td>[0.9843617408170687, 0.7601832993890021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.933909</td>\n",
       "      <td>0.74508</td>\n",
       "      <td>0.435927</td>\n",
       "      <td>[0.9456521739130435, 0.7160493827160493]</td>\n",
       "      <td>[0.9840720221606648, 0.4152744630071599]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy        f1       nll  \\\n",
       "1  train  0.948935    0.7389    0.3364   \n",
       "   test   0.894338  0.636654  0.460383   \n",
       "2  train   0.87698  0.699279  0.336004   \n",
       "   test   0.790149  0.586061  0.521678   \n",
       "3  train  0.849163  0.665361  0.361623   \n",
       "   test   0.751842  0.551804  0.553447   \n",
       "4  train   0.95354  0.808503  0.244142   \n",
       "   test   0.890339  0.644035  0.435605   \n",
       "5  train  0.940998  0.802461  0.233504   \n",
       "   test   0.840244  0.625963  0.466015   \n",
       "6  train  0.947699  0.809268  0.243121   \n",
       "   test   0.892444  0.660857   0.45323   \n",
       "7  train  0.959904  0.811412  0.251877   \n",
       "   test   0.936224  0.706117  0.477989   \n",
       "8  train   0.93411  0.800068  0.220587   \n",
       "   test   0.853505  0.645018  0.450793   \n",
       "9  train  0.954738  0.837576  0.197617   \n",
       "   test    0.90844  0.673566  0.432827   \n",
       "10 train  0.947999  0.828947  0.191406   \n",
       "   test   0.896443  0.672389  0.433336   \n",
       "11 train  0.962562  0.843118  0.209256   \n",
       "   test   0.929489   0.71733  0.431287   \n",
       "12 train  0.961589  0.851849  0.182364   \n",
       "   test   0.931172  0.749499  0.366148   \n",
       "13 train  0.963386  0.864034  0.175074   \n",
       "   test   0.913071  0.698497  0.433779   \n",
       "14 train  0.949459  0.833029  0.187926   \n",
       "   test   0.883393  0.695248   0.38541   \n",
       "15 train  0.956797  0.852438  0.165108   \n",
       "   test    0.91265  0.688575   0.45094   \n",
       "16 train  0.961589  0.863005  0.163038   \n",
       "   test   0.909282  0.712691  0.397953   \n",
       "17 train  0.964621  0.870194  0.170055   \n",
       "   test   0.914123  0.690275  0.474155   \n",
       "18 train   0.96552  0.866446  0.171757   \n",
       "   test   0.921701  0.708548  0.452595   \n",
       "19 train  0.962675  0.869906  0.149125   \n",
       "   test   0.913702  0.703243  0.454537   \n",
       "20 train  0.967878  0.879744  0.155042   \n",
       "   test   0.933909   0.74508  0.435927   \n",
       "\n",
       "                                          precision  \\\n",
       "1  train    [0.9510435554183866, 0.879746835443038]   \n",
       "   test   [0.9332579185520362, 0.37462235649546827]   \n",
       "2  train   [0.9769747077388096, 0.3431419079259611]   \n",
       "   test   [0.9440745672436751, 0.20983935742971888]   \n",
       "3  train  [0.9760569852941177, 0.29145627146031106]   \n",
       "   test   [0.9387698302254384, 0.17184801381692574]   \n",
       "4  train   [0.9662038873462911, 0.7408394403730846]   \n",
       "   test   [0.9359414321665522, 0.36578947368421055]   \n",
       "5  train   [0.9761229605885012, 0.5815811606391926]   \n",
       "   test   [0.9449564134495642, 0.26902173913043476]   \n",
       "6  train   [0.9722896440129449, 0.6423907584128579]   \n",
       "   test    [0.9397008055235904, 0.3866995073891626]   \n",
       "7  train   [0.9612327592924491, 0.9272727272727272]   \n",
       "   test              [0.9357560025957171, 0.953125]   \n",
       "8  train    [0.982211034193413, 0.5354659248956884]   \n",
       "   test    [0.9477832512315271, 0.2995658465991317]   \n",
       "9  train    [0.9774442190669371, 0.683163512857836]   \n",
       "   test    [0.9379635873229939, 0.4735099337748344]   \n",
       "10 train   [0.9816479709666777, 0.6167275680064962]   \n",
       "   test    [0.9415823367065317, 0.4094292803970223]   \n",
       "11 train   [0.9698468600371968, 0.8347222222222223]   \n",
       "   test     [0.940683572216097, 0.6944444444444444]   \n",
       "12 train   [0.9753135895483509, 0.7667804323094426]   \n",
       "   test     [0.948488241881299, 0.6608391608391608]   \n",
       "13 train   [0.9792716860910594, 0.7575757575757576]   \n",
       "   test    [0.9426248023492206, 0.5092592592592593]   \n",
       "14 train   [0.9820346944661914, 0.6257166257166257]   \n",
       "   test   [0.9549614643545279, 0.38731218697829717]   \n",
       "15 train   [0.9829287264093012, 0.6773204903677759]   \n",
       "   test    [0.9402112834344797, 0.5066225165562914]   \n",
       "16 train   [0.9816837915769808, 0.7246168582375478]   \n",
       "   test   [0.9484939066452058, 0.48507462686567165]   \n",
       "17 train   [0.9809262102966136, 0.7592875318066158]   \n",
       "   test    [0.9401076716016151, 0.5187713310580204]   \n",
       "18 train   [0.9770925110132158, 0.7995404939689833]   \n",
       "   test     [0.9417670682730924, 0.587360594795539]   \n",
       "19 train   [0.9842985318107668, 0.7206754906435417]   \n",
       "   test     [0.9436651583710407, 0.513595166163142]   \n",
       "20 train    [0.981031774797632, 0.7941489361702128]   \n",
       "   test    [0.9456521739130435, 0.7160493827160493]   \n",
       "\n",
       "                                             recall  \n",
       "1  train  [0.9961611508465673, 0.35386965376782076]  \n",
       "   test   [0.9522160664819944, 0.29594272076372313]  \n",
       "2  train   [0.8881480583505071, 0.7362525458248472]  \n",
       "   test    [0.8183287165281625, 0.4988066825775656]  \n",
       "3  train    [0.8582454438921889, 0.734725050916497]  \n",
       "   test    [0.778624192059095, 0.47494033412887826]  \n",
       "4  train   [0.9842809229401543, 0.5661914460285132]  \n",
       "   test    [0.9443674976915974, 0.3317422434367542]  \n",
       "5  train   [0.9597931062350992, 0.7041751527494908]  \n",
       "   test   [0.8758079409048938, 0.47255369928400953]  \n",
       "6  train   [0.9712288358184831, 0.6512219959266803]  \n",
       "   test    [0.9425207756232687, 0.3747016706443914]  \n",
       "7  train  [0.9969289206772538, 0.49338085539714865]  \n",
       "   test    [0.9986149584487535, 0.2911694510739857]  \n",
       "8  train   [0.9460136582211985, 0.7841140529531568]  \n",
       "   test   [0.8882733148661126, 0.49403341288782815]  \n",
       "9  train    [0.973612963187457, 0.7169042769857433]  \n",
       "   test    [0.9632963988919667, 0.3412887828162291]  \n",
       "10 train   [0.9618539620964157, 0.7734215885947047]  \n",
       "   test    [0.9450600184672207, 0.3937947494033413]  \n",
       "11 train   [0.9903826726471896, 0.6120162932790224]  \n",
       "   test   [0.9847645429362881, 0.35799522673031026]  \n",
       "12 train   [0.9834323352325535, 0.6863543788187373]  \n",
       "   test    [0.9776084949215144, 0.4510739856801909]  \n",
       "13 train   [0.9812502525558654, 0.7382892057026477]  \n",
       "   test    [0.9632963988919667, 0.3937947494033413]  \n",
       "14 train   [0.9630662302501314, 0.7780040733197556]  \n",
       "   test    [0.9152816251154201, 0.5536992840095465]  \n",
       "15 train   [0.9702186123570534, 0.7876782077393075]  \n",
       "   test   [0.9656048014773777, 0.36515513126491644]  \n",
       "16 train   [0.9767648603871176, 0.7703665987780041]  \n",
       "   test   [0.9522160664819944, 0.46539379474940334]  \n",
       "17 train   [0.9808865721097507, 0.7596741344195519]  \n",
       "   test    [0.9674515235457064, 0.3627684964200477]  \n",
       "18 train   [0.9858972804784418, 0.7087576374745418]  \n",
       "   test    [0.974376731301939, 0.37708830548926014]  \n",
       "19 train   [0.9752697296642017, 0.8039714867617108]  \n",
       "   test   [0.9628347183748845, 0.40572792362768495]  \n",
       "20 train   [0.9843617408170687, 0.7601832993890021]  \n",
       "   test    [0.9840720221606648, 0.4152744630071599]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in trainer.epoch_state.items() for innerKey, values in innerDict.items()}\n",
    "pd.DataFrame(reform).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Insight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
